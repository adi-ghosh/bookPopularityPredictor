{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b67be204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b08cdf28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ShortStories/An_Occurance_at_Owl_Creek_Bridge.txt', 'ShortStories/Bartleby, the Scrivener.txt', 'ShortStories/Rip_Van_Winkle.txt', 'ShortStories/Tell_Tale_Heart.txt', 'ShortStories/The_Last_Question.txt', 'ShortStories/The_Lottery.txt', 'ShortStories/The_Monkeys_Paw.txt', 'ShortStories/The_Most_Dangerous_Game.txt', 'ShortStories/The_Turn_of_the_Screw.txt', 'ShortStories/The_Yellow_Wallpaper.txt']\n"
     ]
    }
   ],
   "source": [
    "# read text data from data_list.txt\n",
    "my_file = open(\"data_list_short.txt\", \"r\")\n",
    "path_data = my_file.read()\n",
    "paths = path_data.split(\"\\n\")\n",
    "print(paths)\n",
    "my_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af4e62fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = []\n",
    "\n",
    "for path in paths:\n",
    "    with open(path, 'r', encoding='utf-8') as f:  # encoding='utf-8'不行\n",
    "        for line in f.readlines():\n",
    "            contents.append(line)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2609881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.56, 4.1, 3.69, 4.3, 4.59, 4.04, 3.78, 4.15, 3.34, 3.69]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read rate scores from rate.txt\n",
    "rate = []\n",
    "rate_str = []\n",
    "my_file = open(\"rate_short.txt\", \"r\")\n",
    "rate_data = my_file.read()\n",
    "rate_str = rate_data.split(\"\\n\")\n",
    "for score in rate_str:\n",
    "    rate.append(float(score))\n",
    "print(rate)\n",
    "my_file.close()\n",
    "\n",
    "# lb = LabelEncoder()\n",
    "# rate = lb.fit_transform(rate)\n",
    "type(rate[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99219692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0  ﻿A man stood upon a railroad bridge in norther...   2.56\n",
      "1  ﻿A Story of Wall-Street  I AM A rather elderly...   4.10\n",
      "2  ﻿Whoever has made a voyage up the Hudson must ...   3.69\n",
      "3  ﻿TRUE!—NERVOUS—VERY, very dreadfully nervous I...   4.30\n",
      "4  ﻿The last question was asked for the first tim...   4.59\n",
      "5  ﻿The morning of June 27th was clear and sunny,...   4.04\n",
      "6  ﻿PART ONE Outside, the night was cold and wet,...   3.78\n",
      "7  ﻿The Most Dangerous Game “OFF THERE to the rig...   4.15\n",
      "8  ﻿The story had held us, round the fire, suffic...   3.34\n",
      "9  ﻿It is very seldom that mere ordinary people l...   3.69\n"
     ]
    }
   ],
   "source": [
    "# build data frame (\"test\", \"label\")\n",
    "data = pd.DataFrame([])\n",
    "data[\"text\"] = contents\n",
    "data[\"label\"] = rate\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4559a2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the text data\n",
    "token = re.compile('[A-Za-z]+|[!?,.()]')\n",
    "def reg_text(text):\n",
    "    new_text = token.findall(text)\n",
    "    new_text = [word.lower() for word in new_text]\n",
    "    return new_text\n",
    "\n",
    "data['text'] = data.text.apply(reg_text)\n",
    "word_set = set()\n",
    "for text in data.text:\n",
    "    for word in text:\n",
    "        word_set.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3da95127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data_ok:  (10, 49644)\n"
     ]
    }
   ],
   "source": [
    "# make dataset for training, make sure the size of each book's vector is the same\n",
    "max_word = len(word_set) + 1\n",
    "word_list = list(word_set)\n",
    "\n",
    "word_index = dict((word, word_list.index(word) + 1) for word in word_list)\n",
    "data_ok = data.text.apply(lambda x: [word_index.get(word, 0) for word in x])\n",
    "\n",
    "maxlen = max(len(x) for x in data_ok)\n",
    "data_ok = tf.keras.preprocessing.sequence.pad_sequences(data_ok.values, maxlen=maxlen)\n",
    "print(\"Shape of data_ok: \", data_ok.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb0bc59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build ther model and train\n",
    "def train_model():\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Embedding(max_word, 16, input_length=maxlen))\n",
    "    model.add(layers.Bidirectional(layers.LSTM(64,\n",
    "                         dropout=0.2,\n",
    "                         recurrent_dropout=0.5)))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "88134a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 49644, 16)         139552    \n",
      "_________________________________________________________________\n",
      "bidirectional_7 (Bidirection (None, 128)               41472     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 181,153\n",
      "Trainable params: 181,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = train_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3b7c140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6811 - acc: 0.0000e+00 - val_loss: 0.5250 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4487 - acc: 0.0000e+00 - val_loss: 0.3624 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "learning_rate_reduction = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.3, min_lr=0.00001)\n",
    "history = model.fit(data_ok,\n",
    "                     data.label.values,\n",
    "                     epochs=50,\n",
    "                     batch_size=128,\n",
    "                     validation_split=0.2,\n",
    "                     callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4bf166c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save the model as model1.keras\n",
    "model.save('model/model1.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf01ec72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
